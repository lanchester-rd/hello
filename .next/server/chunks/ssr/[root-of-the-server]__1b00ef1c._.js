module.exports=[93695,(a,b,c)=>{b.exports=a.x("next/dist/shared/lib/no-fallback-error.external.js",()=>require("next/dist/shared/lib/no-fallback-error.external.js"))},70864,a=>{a.n(a.i(33290))},43619,a=>{a.n(a.i(79962))},13718,a=>{a.n(a.i(85523))},18198,a=>{a.n(a.i(45518))},62212,a=>{a.n(a.i(66114))},54430,a=>{a.n(a.i(3494))},13199,a=>{"use strict";var b=a.i(7997);function c({label:a,title:c,description:d,align:e="left"}){return(0,b.jsxs)("div",{className:`space-y-4 max-w-3xl ${"center"===e?"mx-auto text-center":""}`,children:[(0,b.jsxs)("div",{className:`flex items-center gap-3 ${"center"===e?"justify-center":""}`,children:[(0,b.jsx)("span",{className:"h-px w-6 bg-accent/40"}),(0,b.jsx)("span",{className:"analytical-label text-accent",children:a})]}),(0,b.jsx)("h2",{className:"text-4xl md:text-5xl lg:text-6xl font-bold tracking-tightest uppercase leading-none",children:c}),d&&(0,b.jsx)("p",{className:"text-muted text-lg leading-relaxed max-w-2xl font-medium",children:d})]})}a.s(["default",()=>c])},1871,a=>{"use strict";a.s(["experiments",0,[{slug:"autonomous-dispatch",target:"Autonomous Dispatch",focus:"Coordination Mechanics",note:"Testing LLM-based priority weighting for emergency resource allocation in multi-point crisis scenarios.",full_description:"A structural investigation into how decentralized AI agents can manage resource allocation in environments with radical uncertainty. We are building a simulation layer that allows LLM-based dispatchers to weigh competing high-priority signals in real-time, reducing cognitive load for human coordinators while maintaining strictly governed safety protocols.",status:"Active",hypothesis:"Decentralized LLM weighting reduces dispatch latency by 40% in multi-point crisis scenarios.",tech_stack:["Python","LangChain","Agentic Workflows","Discrete Event Simulation"]},{slug:"regulatory-extraction",target:"Regulatory Extraction",focus:"Data Intelligence",note:"Developing zero-shot extraction protocols for international maritime and transport law updates.",full_description:"Regulatory environments in maritime and international transport are increasingly volatile. This research focus involves the development of zero-shot RAG (Retrieval-Augmented Generation) pipelines designed specifically for high-density legal and regulatory documentation. The goal is to surface mission-critical signals from thousands of pages of updates with 99.9% extraction accuracy.",status:"Active",hypothesis:"Zero-shot extraction protocols can identify critical regulatory shifts faster than dedicated legal compliance teams.",tech_stack:["PyTorch","Rust","Vector Databases","Custom LLM Embeddings"]},{slug:"low-bandwidth-sync",target:"Low-Bandwidth Sync",focus:"Networking",note:"Engineering mesh-based state synchronization for coordination tools in high-interference environments.",full_description:"Coordination fails when connectivity is lost. We are researching mesh-based state synchronization protocols that allow tactical teams to maintain a shared operational picture in environments with low or intermittent bandwidth. This involves custom CRDT (Conflict-free Replicated Data Types) implementations optimized for high-interference radio environments.",status:"Active",hypothesis:"Optimized CRDTs can maintain state consistency in 90% packet loss environments.",tech_stack:["Go","CRDTs","p2p Networking","Protocol Buffers"]},{slug:"predictive-aridity-mapping",target:"Predictive Aridty Mapping",focus:"Environmental Intelligence",note:"Using satellite CV to predict agricultural resource scarcity shifts before they impact market pricing.",full_description:"Environmental volatility is the ultimate strategic bottleneck. We are developing computer vision models that analyze hyperspectral satellite imagery to detect early indicators of resource scarcity (aridty, soil exhaustion, irrigation failure). By mapping these shifts, we can predict supply chain disruptions months before they manifest in market signals.",status:"Active",hypothesis:"Hyperspectral CV signatures can predict crop failure 4-6 weeks before traditional infrared sensing.",tech_stack:["Computer Vision","Satellite OSINT","TensorFlow","Geospatial Data Processing"]},{slug:"predictive-roof-maintenance",target:"Predictive Roof Maintenance",focus:"Asset Intelligence",note:"Developing multimodal predictive models to forecast high-cost building maintenance needs and structural failures.",full_description:"A structural investigation into predicting high-cost building maintenance needs using multimodal historical data. By constructing canonical data models across buildings, roof elements, and intervention history, we are training gradient-boosted trees and survival models to forecast time-to-next-job and cost bands. Phase two incorporates computer vision on inspection photos and 3D risk features to predict failures months before reactive callouts occur.",status:"Active",hypothesis:"Multimodal predictive models incorporating history, transcript-derived signals, and computer vision can forecast roof element failures months before reactive callouts, significantly reducing cost.",tech_stack:["XGBoost","Survival Models","Computer Vision","LiDAR","Next.js"]}]])},96966,a=>{"use strict";var b=a.i(7997),c=a.i(13199),d=a.i(1871),e=a.i(95936);function f(){return(0,b.jsx)("div",{className:"bg-black min-h-screen",children:(0,b.jsx)("main",{className:"pt-32 pb-24 px-6 md:px-12",children:(0,b.jsxs)("div",{className:"max-w-7xl mx-auto space-y-24",children:[(0,b.jsx)(c.default,{label:"Experiments",title:"Intelligence.",description:"Ongoing technical investigations into the future of operational systems."}),(0,b.jsx)("div",{className:"border border-white/10 overflow-hidden",children:(0,b.jsxs)("table",{className:"w-full text-left border-collapse",children:[(0,b.jsx)("thead",{children:(0,b.jsxs)("tr",{className:"border-b border-white/10 bg-white/[0.02]",children:[(0,b.jsx)("th",{className:"p-6 text-[10px] font-bold uppercase tracking-widest text-white/30 w-1/4",children:"Target"}),(0,b.jsx)("th",{className:"p-6 text-[10px] font-bold uppercase tracking-widest text-white/30 w-1/4",children:"Primary Focus"}),(0,b.jsx)("th",{className:"p-6 text-[10px] font-bold uppercase tracking-widest text-white/30",children:"Current Notes"})]})}),(0,b.jsx)("tbody",{className:"divide-y divide-white/5",children:d.experiments.map((a,c)=>(0,b.jsxs)("tr",{className:"hover:bg-white/[0.01] transition-colors group",children:[(0,b.jsx)("td",{className:"p-6 align-top",children:(0,b.jsxs)(e.default,{href:`/research/${a.slug}`,className:"block group/link",children:[(0,b.jsx)("span",{className:"text-lg font-bold uppercase tracking-tight group-hover/link:text-accent transition-colors",children:a.target}),(0,b.jsx)("span",{className:"ml-2 inline-block opacity-0 group-hover/link:opacity-100 group-hover/link:translate-x-1 transition-all text-accent",children:"â†’"})]})}),(0,b.jsx)("td",{className:"p-6 align-top",children:(0,b.jsx)("span",{className:"text-xs px-2 py-1 border border-white/10 text-white/40 uppercase tracking-tighter",children:a.focus})}),(0,b.jsx)("td",{className:"p-6 align-top",children:(0,b.jsx)("p",{className:"text-sm text-white/50 leading-relaxed max-w-xl",children:a.note})})]},c))})]})}),(0,b.jsxs)("div",{className:"bg-surface border border-surface-border p-12 text-center space-y-4",children:[(0,b.jsx)("h3",{className:"text-xs font-bold uppercase tracking-[0.3em] text-white/20",children:"Collaborations"}),(0,b.jsx)("p",{className:"text-lg text-white/60",children:"We occasionally open research cohorts to academic and technical partners. Inquiry via partner channel."})]})]})})})}a.s(["default",()=>f])}];

//# sourceMappingURL=%5Broot-of-the-server%5D__1b00ef1c._.js.map